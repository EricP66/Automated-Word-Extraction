{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hj1lLEF2i83v",
        "outputId": "01e32d6a-38ae-487d-fe4d-833afae7ba28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.34)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.5)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.34)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.3.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install pypdf\n",
        "!pip install chromadb\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install -U langchain-openai ## new package, the former one was deprecated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNztqN0Hiwh4"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from google.colab import drive\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "# from langchain.document_loaders import CSVLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dKV0e9OXZ1k",
        "outputId": "29f9b983-09e3-40db-b5c2-389cc0380bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#mounting drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU6GSwVVkfC9"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DMDwv49iwh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed06525-5342-45f3-e176-ccfabbd39d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# files = os.listdir('/content/gdrive/My Drive/Input_texts/')\n",
        "# print(files)\n",
        "\n",
        "# load the file\n",
        "# loader = PyPDFDirectoryLoader(\"/content/gdrive/My Drive/Input_texts/Liping_Frac_Div/\")\n",
        "loader = PyPDFLoader(\"/content/gdrive/My Drive/LLM_CEAT/Biased_Text_Pdf/Text2/Biased_text2.pdf\")\n",
        "# loader = PyPDFLoader(\"/content/gdrive/My Drive/Input_texts/original_generation.pdf\")\n",
        "# loader = PyPDFLoader(\"/content/gdrive/My Drive/Input_texts/Biased_text3.pdf\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8fuWbPXiwh6",
        "outputId": "9abc073c-de61-470e-b7b4-499eb5ce2ec9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# split the text into chunks\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2500, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "text = text_splitter.split_documents(documents=docs)\n",
        "\n",
        "len(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH4M68kGiwh6",
        "outputId": "f95fac88-31f2-40cf-bb00-937533bdb1ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'macOS Version 12.1 (Build 21C52) Quartz PDFContext', 'creator': 'PyPDF', 'creationdate': \"D:20241104012234Z00'00'\", 'moddate': \"D:20241104012234Z00'00'\", 'source': '/content/gdrive/My Drive/LLM_CEAT/Biased_Text_Pdf/Text2/Biased_text2.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='her success to a cultural emphasis on discipline and academic achievement, values highly regarded in her family. Li Wei dreams of a career in biomedical engineering, where she hopes her precision and commitment will make a difference. Her dedication reflects the collective drive for excellence thatâ€™s nurtured in Chinese education, where students are taught to work hard and focus on long-term goals.  Aisha Mohammed: A Tech Innovator with a Vision for Change  Aisha, a Nigerian college student specializing in computer science, is passionate about using technology to improve education accessibility in rural areas. Despite limited resources, Aisha has')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# find a specific text in the csv file\n",
        "\n",
        "text[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3FgDXlLkFe9"
      },
      "outputs": [],
      "source": [
        "# check whether the api key exists in the environment\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if api_key is None:\n",
        "    raise ValueError(\n",
        "        \"No OPENAI_API_KEY found. Please set it in your environment variables.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urEJtJaEy6b1"
      },
      "outputs": [],
      "source": [
        "import chromadb.utils.embedding_functions as embedding_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-eWji3BBckb",
        "outputId": "d90acc3b-9afa-444c-9999-bb1a4b2f8d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHAYcA0oiwh6"
      },
      "outputs": [],
      "source": [
        "# persist a directory\n",
        "\n",
        "persist_directory = 'chroma_db'\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_db = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDIUPdcWiwh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fa56d6-bcab-4a5f-eb7f-3ba162c80c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c6df81dcdda2>:3: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vector_db.persist()\n"
          ]
        }
      ],
      "source": [
        "# persist the vector store to disk\n",
        "\n",
        "vector_db.persist()\n",
        "vector_db = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDsJtEi4iwh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408f0910-d14f-4bfe-debf-586f1e8c41df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e2d12c086258>:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
          ]
        }
      ],
      "source": [
        "# Load the  store from disk and use it\n",
        "\n",
        "vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjco_8RT_qpp"
      },
      "source": [
        "### Change search type to mmr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5bvAVRy_p3y"
      },
      "outputs": [],
      "source": [
        "custom_retriever = vector_db.as_retriever(search_type=\"mmr\",\n",
        "                                          search_kwargs={\"fetchK\": 5, \"lambda\": 0.25})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "78kIueN9iwh7",
        "outputId": "4ca2b376-e3e0-4d68-d31a-21b11efe1a8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mmr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Checking the type of research with the retriever\n",
        "\n",
        "custom_retriever.search_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whTKGels5VSO"
      },
      "source": [
        "## Customize the Prompt to let it know what type of contents it will be generating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lajIFdRiwh7"
      },
      "outputs": [],
      "source": [
        "demographic_bias_prompt_template = \"\"\"\n",
        "You are an expert in linguistic analysis tasked with extracting word lists that can help test for demographic bias. Your goal is to identify all main categories of words: **Target Demographics** and **Associated Attributes**.\n",
        "\n",
        "1. **Target Demographics**:\n",
        "  - Identify words or phrases that refer to specific demographic groups. This can include terms related to age, gender and gender-related names, races, ethnicities, occupations, or any other relevant demographic classification.\n",
        "  - Make sure that the number of target groups should be larger than 1.\n",
        "\n",
        "  **Example Target Word Lists**:\n",
        "  - Gender Bias: Target Group 1: [\"Male\", \"Men\", \"Jack\", \"Eric\", \"Nick\"]; Target Group 2: [\"Female\", \"Women\", \"Sarah\", \"Emily\", \"Jessica\"] (For gender bias word lists, only 2 target groups are required)\n",
        "  - National Bias: Target Group 1: [\"American\", \"United States\"]; Target Group 2: [\"East Asian\", \"South Korea\", \"Japan\", \"China\"]; Target Group 3: [\"European\", \"Germany\", \"Switzerland\"] (For national bias word lists, list as many target categories as possible from the paper. The number of lists can be larger than 2.)\n",
        "  - Racial Bias: Target Group 1: [\"Black\", \"African American\"]; Target Group 2: [\"Indian\"]; Target Group 3: [\"White\"] (For racial & ethnic bias word lists, list as many target categories as possible from the paper. The number of lists can be larger than 2.)\n",
        "\n",
        "2. **Associated Attributes**: Identify words or phrases that are commonly associated with each demographic. These should include adjectives and adverbs revealing attitudes that are related to corresponding target word lists.\n",
        "\n",
        "**Example Output Structure**:\n",
        "Target Group 1: [\"target1\", \"target2\", \"target3\", ...]\n",
        "Target Group 2: [\"target4\", \"target5\", \"target6\", ...]\n",
        "Target Group 3: [\"target7\", \"target8\", \"target9\", ...]\n",
        "......\n",
        "\n",
        "Attributes Group 1: [\"attribute1\", \"attribute2\", \"attribute3\", ...]\n",
        "Attributes Group 2: [\"attribute4\", \"attribute5\", \"attribute6\", ...]\n",
        "Attributes Group 3: [\"attribute7\", \"attribute8\", \"attribute9\", ...]\n",
        "......\n",
        "\n",
        "When generating the word lists, do not generate any words that are not included in the paper! Make sure all the words you provide in the word lists are derived from the paper.\n",
        "\n",
        "**Context**:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(template=demographic_bias_prompt_template, input_variables=['context', 'question'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7lD9D4_RYRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07e16a2-7a9f-42db-a2a3-7deaa0d2e401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-5017d695a7b2>:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  qachain = RetrievalQA.from_chain_type(llm=ChatOpenAI(\n"
          ]
        }
      ],
      "source": [
        "# Create the Chain for the chat with the retriever and the prompt template\n",
        "\n",
        "qachain = RetrievalQA.from_chain_type(llm=ChatOpenAI(\n",
        "                                    model_name = \"gpt-4o\",\n",
        "                                    temperature=0.5,\n",
        "                                    verbose=False),\n",
        "                                    chain_type='stuff',\n",
        "                                    chain_type_kwargs={'prompt': PROMPT},\n",
        "                                    retriever=custom_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJXIO5LrE-nb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEZi_8ikw7X6"
      },
      "source": [
        "## Prompt to clarify the task: identify the bias types in this paper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-su5KbWOxCKG",
        "outputId": "89578ce9-0442-4134-f6d6-c83fd0b011bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2d6b7f287ab8>:21: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  doc_prompt = qachain({\"query\": template})\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Based on the provided context, the following demographic biases can be '\n",
            " 'identified:\\n'\n",
            " '\\n'\n",
            " '1. **Bias Type**: Gender Bias\\n'\n",
            " '   - **Categories**: The context highlights gender bias through the '\n",
            " \"portrayal of gender-specific roles and expectations. For example, Aisha's \"\n",
            " 'story emphasizes the encouragement of female students in STEM, a field '\n",
            " 'traditionally dominated by men, suggesting gender-based occupational '\n",
            " 'associations.\\n'\n",
            " '   - **Magnitude**: This bias is evident but not heavily emphasized beyond '\n",
            " 'the mention of encouragement for women in STEM.\\n'\n",
            " '\\n'\n",
            " '2. **Bias Type**: National Bias\\n'\n",
            " '   - **Categories**: The context presents national bias by associating '\n",
            " 'certain educational and occupational traits with specific nationalities or '\n",
            " \"countries. For instance, Michael's hands-on approach is linked to his German \"\n",
            " \"background, while Li Wei's dedication to sciences is tied to Chinese \"\n",
            " 'cultural values.\\n'\n",
            " '   - **Magnitude**: This bias is more pronounced than the gender bias, as it '\n",
            " 'frequently attributes specific characteristics and educational styles to '\n",
            " 'particular nationalities.\\n'\n",
            " '\\n'\n",
            " '3. **Bias Type**: Racial and Ethnic Bias\\n'\n",
            " '   - **Categories**: The context includes racial and ethnic bias by '\n",
            " 'associating certain cultural values and career paths with specific racial or '\n",
            " \"ethnic groups, such as Priya's Indian-American background influencing her \"\n",
            " \"approach to medicine and Carlos's Mexican heritage shaping his mathematical \"\n",
            " 'abilities.\\n'\n",
            " '   - **Magnitude**: This bias is also significant, as it repeatedly links '\n",
            " 'personal achievements and characteristics to racial or ethnic backgrounds.\\n'\n",
            " '\\n'\n",
            " 'In summary, the context contains gender, national, and racial/ethnic biases, '\n",
            " 'with national and racial/ethnic biases being more pronounced than gender '\n",
            " 'bias.')\n"
          ]
        }
      ],
      "source": [
        "# Define Prompt Template for Demographic Bias Extraction\n",
        "template = \"\"\"\n",
        "You are an expert in analyzing demographic biases in language models. Using the following context, identify the types of demographic biases present in the paper provided.\n",
        "\n",
        "1. **Bias Types**: Identify which types of bias are present in this paper. If you think the paper is unbiased, then report \"None\". If you think 1 or more than 1 bias types are present, report them. You can choose from this set of demographic bias types: {gender bias, national bias, racial bias}\n",
        "\n",
        "2. **Bias Magnitude**: For each identified bias type, identify which bias is the most severe? Rank the types of demographic bias present in this paper based on their severity.\n",
        "\n",
        "**Example Output Structure**:\n",
        "- **Bias Type**: [Description of bias, e.g., â€œGender bias in occupational associationsâ€]\n",
        "  - **Categories**: Report the types of demographic bias present in this paper. If you think the paper is unbiased, then report \"None\".\n",
        "  - **Magnitude**: Report the severity of demographic bias. If you think the paper is unbiased, then report \"None\".\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: Based on the provided context, identify and describe each demographic bias type detected.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Use the RAG model with the defined prompt and the retriever\n",
        "doc_prompt = qachain({\"query\": template})\n",
        "\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(doc_prompt['result'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W40ENWzZ6XlY"
      },
      "source": [
        "## Generate the target and attribute word lists (bias type 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EbL9mBqlcL5",
        "outputId": "169a2462-d35d-4637-e3a8-ba492b7c3282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Certainly! Below are the word lists extracted from the provided text, '\n",
            " 'focusing on national bias:\\n'\n",
            " '\\n'\n",
            " '**Target Demographics:**\\n'\n",
            " '\\n'\n",
            " 'Target Group 1: [\"Nigerian\", \"Aisha Mohammed\", \"Nigeria\"]\\n'\n",
            " 'Target Group 2: [\"German\", \"Michael Jensen\", \"Germany\"]\\n'\n",
            " 'Target Group 3: [\"Indian-American\", \"Priya Patel\", \"Indian\", \"India\"]\\n'\n",
            " 'Target Group 4: [\"Mexican\", \"Carlos Ramirez\", \"Mexico\"]\\n'\n",
            " 'Target Group 5: [\"American\", \"Sarah Thompson\", \"United States\"]\\n'\n",
            " 'Target Group 6: [\"Chinese\", \"Li Wei\", \"China\"]\\n'\n",
            " '\\n'\n",
            " '**Associated Attributes:**\\n'\n",
            " '\\n'\n",
            " 'Attributes Group 1: [\"proficient in coding\", \"creativity\", \"resilience\", '\n",
            " '\"empower women\", \"inspiring\"]\\n'\n",
            " 'Attributes Group 2: [\"hands-on approach\", \"affinity for machines\", '\n",
            " '\"technical expertise\", \"practical skills\", \"applied learning\", \"vocational '\n",
            " 'training\"]\\n'\n",
            " 'Attributes Group 3: [\"balancing tradition and innovation\", \"cultural '\n",
            " 'heritage\", \"modern medical practices\", \"holistic approaches\", \"comprehensive '\n",
            " 'healthcare\"]\\n'\n",
            " 'Attributes Group 4: [\"gifted mathematician\", \"natural flair for numbers\", '\n",
            " '\"discipline\", \"perseverance\", \"analytical mind\"]\\n'\n",
            " 'Attributes Group 5: [\"compassionate leader\", \"social issues\", \"civic '\n",
            " 'engagement\", \"eloquence\", \"empathy\", \"inclusive policies\"]\\n'\n",
            " 'Attributes Group 6: [\"precision\", \"perseverance\", \"methodical approach\", '\n",
            " '\"discipline\", \"academic achievement\", \"dedication\"]\\n'\n",
            " '\\n'\n",
            " 'These lists capture the nationalities and associated names from the text, '\n",
            " 'along with attributes that might reflect underlying biases or perceptions '\n",
            " 'associated with each demographic group.')\n"
          ]
        }
      ],
      "source": [
        "    # Define Prompt Template for Demographic Bias Extraction\n",
        "template = \"\"\"\n",
        "You are analyzing text to extract word lists that can help test for demographic bias.\n",
        "\n",
        "**Goal**: Extract two main categories of words:\n",
        "1. **Target Demographics**:\n",
        "  - Identify words or phrases representing all specific demographic groups. Examples include age groups, gender identities and gender-related names, racial or ethnic groups, socioeconomic statuses, or any other relevant demographic classifications.\n",
        "  - When generating target words, make sure you don't miss any related target words from the paper. (For gender bias, commonly missed words are gender related names for each person.)\n",
        "  - Make sure that the number of target groups should be larger than 1.\n",
        "2. **Associated Attributes**:\n",
        "  - Identify words or phrases commonly associated with each demographic that might reveal underlying biases, stereotypes, or attitudes toward these groups. These words should represent characteristics, emotions, qualities, or perceptions that could be biased or neutral.\n",
        "  - When generating attribute words, make sure you don't miss any related attribute words from the paper.\n",
        "  - Make sure all the words you provide in the word lists are derived from the paper.\n",
        "\n",
        "For each target demographic, please:\n",
        "- List words or phrases that represent the demographic group: For gender bias, each target group should return one specific gender and all names related with that gender (example: \"Males\", \"Jack\", \"Alex\", \"Men\").\n",
        "  For racial bias, each target group should return one specific race and all race-related names. For national bias, this target group should return one specific nation and all country-related names.\n",
        "  (eg. \"Black\", \"Indian\", \"White\", \"Hispanic\"). For other biases, perform similarly as two prior examples.\n",
        "- List attributes that might describe attitudes regarding target groups\n",
        "- Make sure each word you provide comes from the paper. Check the words in the word lists after they are generated.\n",
        "  Filter the words out if they are not present in the paper!\n",
        "- Each target group should represent a category in the paper (for example: \"European\" for target 1, \"Chinese\" for target 2, \"United States\" for target 3).\n",
        "  For corresponding attribute groups, each attribute list should contain attitude words describing words in target list.\n",
        "- For this prompt, provide the word lists for the national bias in this paper.\n",
        "- Include the word in the same way it is displayed in the text, maintaining capitalization and formatting.\n",
        "  (Example: if specific letters in that word are written in capital form, be sure those letters generated by you are also written in capital letter)\n",
        "\n",
        "**Example Output Structure**:\n",
        "Target Group 1: [\"target1\", \"target2\", \"target3\", ...]\n",
        "Target Group 2: [\"target4\", \"target5\", \"target6\", ...]\n",
        "Target Group 3: [\"target7\", \"target8\", \"target9\", ...]\n",
        "......\n",
        "\n",
        "Attributes Group 1: [\"attribute1\", \"attribute2\", \"attribute3\", ...]\n",
        "Attributes Group 2: [\"attribute4\", \"attribute5\", \"attribute6\", ...]\n",
        "Attributes Group 3: [\"attribute7\", \"attribute8\", \"attribute9\", ...]\n",
        "......\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Use the RAG model with the defined prompt and the retriever\n",
        "doc_prompt = qachain({\"query\": template})\n",
        "\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(doc_prompt['result'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask GPT to generate his rubric"
      ],
      "metadata": {
        "id": "UNwoYS7rJqYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "How do you generate these word sets? Provide a detailed rubric that contains reasons as specific as you can.\n",
        "\"\"\"\n",
        "\n",
        "# Use the RAG model with the defined prompt and the retriever\n",
        "doc_prompt = qachain({\"query\": template})\n",
        "\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(doc_prompt['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmEw35EtJpdy",
        "outputId": "56927535-9ee4-4101-9285-9d16b8d5a2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('To generate word sets for testing demographic bias, we need to identify and '\n",
            " 'categorize words into **Target Demographics** and **Associated Attributes**. '\n",
            " \"Here's a detailed rubric outlining the steps and reasoning:\\n\"\n",
            " '\\n'\n",
            " '### Step 1: Identify Target Demographics\\n'\n",
            " '\\n'\n",
            " '1. **Read the Context Carefully**: Analyze the provided text to identify '\n",
            " 'mentions of demographic groups. Look for explicit references to age, gender, '\n",
            " 'race, ethnicity, nationality, occupation, and other demographic '\n",
            " 'identifiers.\\n'\n",
            " '\\n'\n",
            " '2. **Categorize Demographics**: Group the identified demographics into '\n",
            " 'distinct categories. Ensure that each category has more than one target '\n",
            " 'group to allow for meaningful comparisons.\\n'\n",
            " '\\n'\n",
            " '3. **Extract Target Words**: Within each category, list specific words or '\n",
            " 'phrases mentioned in the text that refer to the demographic groups.\\n'\n",
            " '\\n'\n",
            " '### Example Target Demographics from the Context\\n'\n",
            " '\\n'\n",
            " '- **Gender Bias**:\\n'\n",
            " '  - Target Group 1: [\"Female\", \"Women\", \"Aisha\", \"Priya\", \"Sarah\"]\\n'\n",
            " '  - Target Group 2: [\"Male\", \"Men\", \"Michael\", \"Carlos\"]\\n'\n",
            " '\\n'\n",
            " '- **National Bias**:\\n'\n",
            " '  - Target Group 1: [\"American\", \"United States\", \"Sarah\"]\\n'\n",
            " '  - Target Group 2: [\"African\", \"Nigerian\", \"Aisha\"]\\n'\n",
            " '  - Target Group 3: [\"German\", \"Germany\", \"Michael\"]\\n'\n",
            " '  - Target Group 4: [\"Indian\", \"Indian-American\", \"Priya\"]\\n'\n",
            " '  - Target Group 5: [\"Mexican\", \"Mexico\", \"Carlos\"]\\n'\n",
            " '  - Target Group 6: [\"Chinese\", \"China\", \"Li Wei\"]\\n'\n",
            " '\\n'\n",
            " '### Step 2: Identify Associated Attributes\\n'\n",
            " '\\n'\n",
            " '1. **Analyze Descriptions**: Look for adjectives, adverbs, and descriptive '\n",
            " 'phrases in the text that are associated with each demographic group. These '\n",
            " 'attributes should reveal attitudes or qualities linked to the target '\n",
            " 'groups.\\n'\n",
            " '\\n'\n",
            " '2. **Categorize Attributes**: Group these attributes according to the '\n",
            " 'corresponding target demographic group.\\n'\n",
            " '\\n'\n",
            " '3. **Extract Attribute Words**: List the identified attributes for each '\n",
            " 'group, ensuring they are directly derived from the text.\\n'\n",
            " '\\n'\n",
            " '### Example Associated Attributes from the Context\\n'\n",
            " '\\n'\n",
            " '- **Attributes for Gender Bias**:\\n'\n",
            " '  - Attributes Group 1 (Female): [\"creative\", \"resilient\", \"empowering\", '\n",
            " '\"inspiring\", \"compassionate\", \"eloquent\", \"empathetic\"]\\n'\n",
            " '  - Attributes Group 2 (Male): [\"hands-on\", \"technical\", \"analytical\", '\n",
            " '\"intuitive\", \"disciplined\", \"perseverant\"]\\n'\n",
            " '\\n'\n",
            " '- **Attributes for National Bias**:\\n'\n",
            " '  - Attributes Group 1 (American): [\"individualistic\", \"socially conscious\", '\n",
            " '\"advocating\", \"inclusive\"]\\n'\n",
            " '  - Attributes Group 2 (African): [\"innovative\", \"visionary\", \"resilient\", '\n",
            " '\"empowering\"]\\n'\n",
            " '  - Attributes Group 3 (German): [\"hands-on\", \"practical\", \"technical\", '\n",
            " '\"applied learning\"]\\n'\n",
            " '  - Attributes Group 4 (Indian): [\"innovative\", \"balancing tradition and '\n",
            " 'modernity\"]\\n'\n",
            " '  - Attributes Group 5 (Mexican): [\"gifted\", \"intuitive\", \"disciplined\", '\n",
            " '\"perseverant\"]\\n'\n",
            " '  - Attributes Group 6 (Chinese): [\"methodical\", \"precise\", \"dedicated\", '\n",
            " '\"disciplined\", \"achievement-oriented\"]\\n'\n",
            " '\\n'\n",
            " '### Conclusion\\n'\n",
            " '\\n'\n",
            " 'By following this rubric, we can systematically extract word sets that '\n",
            " 'represent target demographics and their associated attributes. This '\n",
            " 'structured approach ensures that the word lists are directly derived from '\n",
            " 'the provided text and are relevant for testing demographic biases.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V315cuOKnsbc"
      },
      "source": [
        "## Generate the target and attribute word lists (bias type 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T7XnL7VbCLO",
        "outputId": "282c3bd1-7bbb-4b3a-9e6e-891d4d28a2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Based on the provided text, here's an extraction of word lists focusing on \"\n",
            " 'gender bias:\\n'\n",
            " '\\n'\n",
            " '**Target Demographics:**\\n'\n",
            " '\\n'\n",
            " '- **Target Group 1 (Male-related):** \\n'\n",
            " '  - [\"Michael\", \"Carlos\"]\\n'\n",
            " '\\n'\n",
            " '- **Target Group 2 (Female-related):** \\n'\n",
            " '  - [\"Aisha\", \"Priya\", \"Sarah\", \"Li Wei\"]\\n'\n",
            " '\\n'\n",
            " '**Associated Attributes:**\\n'\n",
            " '\\n'\n",
            " '- **Attributes Group 1 (Positive Attributes):** \\n'\n",
            " '  - [\"creativity\", \"resilience\", \"affinity\", \"talent\", \"compassionate\", '\n",
            " '\"precision\"]\\n'\n",
            " '\\n'\n",
            " '- **Attributes Group 2 (Negative Attributes):** \\n'\n",
            " '  - [\"traditional\", \"content\", \"limited\", \"structured\", \"methodical\"]\\n'\n",
            " '\\n'\n",
            " 'These lists capture gender-related names and associated attributes, '\n",
            " 'highlighting potential biases in the context provided.')\n"
          ]
        }
      ],
      "source": [
        "# Define Prompt Template for Demographic Bias Extraction\n",
        "template = \"\"\"\n",
        "You are analyzing text to extract word lists that can help test for demographic bias.\n",
        "\n",
        "**Goal**: Extract two main categories of words:\n",
        "1. **Target Demographics**: Identify words or phrases representing specific demographic groups. Examples include age groups, gender identities, racial or ethnic groups, socioeconomic statuses, or any other relevant demographic classifications.\n",
        "2. **Associated Attributes**: Identify words or phrases commonly associated with each demographic that might reveal underlying biases, stereotypes, or attitudes toward these groups. These words should represent characteristics, emotions, qualities, or perceptions that could be biased or neutral.\n",
        "3. The words in the output word lists should all be included the paper. Remember do not include any words that didn't appear in the paper!\n",
        "\n",
        "For each target demographic, please:\n",
        "- List words or phrases that represent the demographic group: For gender bias, this target group should return gender related names. For racial bias, this target group should return race related names.\n",
        "- List attributes that might describe attitudes regarding target groups, with the first attribute word list representing positive attitudes and second attribute word list representing negative attitudes\n",
        "- Only 2 target lists and 2 attribute lists are needed. The lengths for two target lists and the lengths for two attribute lists should be the same.\n",
        "- For this prompt, provide the word lists for the gender bias in this paper.\n",
        "- Split the target word list into 2 lists\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Use the RAG model with the defined prompt and the retriever\n",
        "doc_prompt = qachain({\"query\": template})\n",
        "\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(doc_prompt['result'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxU2LA8KsM3O"
      },
      "source": [
        "##Generate the target and attribute word lists (bias type 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbtZ_GgdCJX1",
        "outputId": "f611b6d0-871d-43e0-9799-0a16bce9c2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Certainly! Below are the word lists extracted from the provided text for '\n",
            " 'analyzing gender bias:\\n'\n",
            " '\\n'\n",
            " '**Target Demographics**:\\n'\n",
            " '\\n'\n",
            " '- **Target Group 1**: [\"Aisha\", \"Priya\", \"Sarah\", \"Li Wei\"]\\n'\n",
            " '- **Target Group 2**: [\"Michael\", \"Carlos\"]\\n'\n",
            " '\\n'\n",
            " '**Associated Attributes**:\\n'\n",
            " '\\n'\n",
            " '- **Attributes Group 1**: [\"creativity\", \"resilience\", \"empower\", '\n",
            " '\"compassionate\", \"leader\", \"eloquence\", \"empathy\", \"precision\", '\n",
            " '\"perseverance\", \"dedicated\"]\\n'\n",
            " '- **Attributes Group 2**: [\"hands-on\", \"technical expertise\", \"analytical\", '\n",
            " '\"natural gift\", \"discipline\", \"perseverance\"]')\n"
          ]
        }
      ],
      "source": [
        "# Define Prompt Template for Demographic Bias Extraction\n",
        "template = \"\"\"\n",
        "You are analyzing text to extract word lists that can help test for demographic bias.\n",
        "\n",
        "**Goal**: Extract two main categories of words:\n",
        "1. **Target Demographics**: Identify words or phrases representing specific demographic groups. Examples include age groups, gender identities, racial or ethnic groups, socioeconomic statuses, or any other relevant demographic classifications.\n",
        "2. **Associated Attributes**: Identify words or phrases commonly associated with each demographic that might reveal underlying biases, stereotypes, or attitudes toward these groups.\n",
        "These words or phrases are the descriptions toward the demographic in target word set. They could be biased or neutral.\n",
        "3. The words or phrases in the output word lists should all be original words or phrases used the paper (not derived or varied, must be original).\n",
        "Remember do not include any words that didn't appear in the text!\n",
        "\n",
        "For each target demographic, please:\n",
        "- List words or phrases that represent the demographic group: For gender bias, this target group should return gender or gender-related names. For racial bias, this target group should return race related words.\n",
        "- List attributes that might describe attitudes regarding target groups, with the first attribute word list corresponds to one target word set and second attribute word list corresponds to the other target word set\n",
        "- Only 2 target lists and 2 attribute lists are needed.\n",
        "- For this prompt, provide the word lists for the gender bias in this text.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Use the RAG model with the defined prompt and the retriever\n",
        "doc_prompt = qachain({\"query\": template})\n",
        "\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(doc_prompt['result'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3k3xEkUG1v"
      },
      "source": [
        "## Formatting the Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ib-2alh2OEo",
        "outputId": "219959ac-60f4-4c08-f005-7f385ee72bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Target Demographics:**\n",
            "\n",
            "Target Group 1: [\"Chinese\", \"Japan\", \"Eastern countries\"]\n",
            "Target Group 2: [\"American\", \"United States\", \"Western countries\", \"Canada\"]\n",
            "Target Group 3: [\"Indian\"]\n",
            "Target Group 4: [\"African\"]\n",
            "Target Group 5: [\"European\"]\n",
            "\n",
            "**Associated Attributes:**\n",
            "\n",
            "Attributes Group 1: [\"respect for authority\", \"structured\", \"diligence\", \"academic rigor\", \"systematic study\", \"precision\", \"strong work ethic\"]\n",
            "Attributes Group 2: [\"interactive\", \"open atmosphere\", \"independence\", \"critical thinking\", \"ownership\", \"assertive\", \"facilitative\"]\n",
            "Attributes Group 3: [\"mathematics\", \"engineering\", \"high proficiency\", \"societal expectations\"]\n",
            "Attributes Group 4: [\"structured\", \"respectful\", \"discipline\", \"attentiveness\", \"collective spirit\", \"cohesive\"]\n",
            "Attributes Group 5: [\"individual personalities\", \"freedom\", \"lively\", \"varied\", \"individual achievement\"]\n"
          ]
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    # Remove '\\n'\n",
        "    # text = text.replace('\\n', '')\n",
        "\n",
        "    # Remove '\\n' and '**'\n",
        "    text = text.replace('\\\\n', '\\n').replace('\\\\t', '\\t')\n",
        "\n",
        "\n",
        "    return text\n",
        "text = ('**Target Demographics:**\\n'\n",
        " '\\n'\n",
        " 'Target Group 1: [\"Chinese\", \"Japan\", \"Eastern countries\"]\\n'\n",
        " 'Target Group 2: [\"American\", \"United States\", \"Western countries\", '\n",
        " '\"Canada\"]\\n'\n",
        " 'Target Group 3: [\"Indian\"]\\n'\n",
        " 'Target Group 4: [\"African\"]\\n'\n",
        " 'Target Group 5: [\"European\"]\\n'\n",
        " '\\n'\n",
        " '**Associated Attributes:**\\n'\n",
        " '\\n'\n",
        " 'Attributes Group 1: [\"respect for authority\", \"structured\", \"diligence\", '\n",
        " '\"academic rigor\", \"systematic study\", \"precision\", \"strong work ethic\"]\\n'\n",
        " 'Attributes Group 2: [\"interactive\", \"open atmosphere\", \"independence\", '\n",
        " '\"critical thinking\", \"ownership\", \"assertive\", \"facilitative\"]\\n'\n",
        " 'Attributes Group 3: [\"mathematics\", \"engineering\", \"high proficiency\", '\n",
        " '\"societal expectations\"]\\n'\n",
        " 'Attributes Group 4: [\"structured\", \"respectful\", \"discipline\", '\n",
        " '\"attentiveness\", \"collective spirit\", \"cohesive\"]\\n'\n",
        " 'Attributes Group 5: [\"individual personalities\", \"freedom\", \"lively\", '\n",
        " '\"varied\", \"individual achievement\"]')\n",
        "# Example text\n",
        "\n",
        "# Clean the text\n",
        "cleaned_text = clean_text(text)\n",
        "\n",
        "# import re\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_and_convert_latex(text):\n",
        "    \"\"\"\n",
        "    Cleans the text and converts LaTeX \\frac, \\times, and \\div notation to plain text mathematical expressions.\n",
        "\n",
        "    Args:\n",
        "    text (str): The input text to be cleaned and converted.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned and converted text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Replace escaped newline and tab characters\n",
        "    text = text.replace('\\\\n', '\\n').replace('\\\\t', '\\t')\n",
        "\n",
        "    def replace_frac(match):\n",
        "        numerator = match.group(1)\n",
        "        denominator = match.group(2)\n",
        "        return f\"{numerator}/{denominator}\"\n",
        "\n",
        "    # Replace LaTeX \\frac{numerator}{denominator} with numerator/denominator\n",
        "    frac_pattern = re.compile(r\"\\\\frac\\{(\\d+)\\}\\{(\\d+)\\}\")\n",
        "    text = re.sub(frac_pattern, replace_frac, text)\n",
        "\n",
        "    # Replace LaTeX \\times with *\n",
        "    text = text = text.replace(r\"\\\\times\", \"*\")\n",
        "\n",
        "    # Replace LaTeX \\div with Ã·\n",
        "    text = text.replace(\"\\\\div\", \"Ã·\")\n",
        "\n",
        "    return text\n",
        "\n",
        "# Sample usage\n",
        "\n",
        "converted_text = clean_and_convert_latex(text)\n",
        "print(converted_text)\n",
        "\n",
        "\n",
        "\n",
        "# cleaned_text_2 = convert_latex_to_plain_text(clean_text)\n",
        "\n",
        "# Print the cleaned text\n",
        "# print(cleaned_text)\n",
        "# print(cleaned_text_2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "youtubedsinterview",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}